The CIFAR-10 dataset is a collection of images that are commonly used to train machine learning and computer vision algorithms. It is one of the most widely used datasets for machine learning research. It consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. [Image Classification – Deep Learning Project in Python with Keras] 
 
The dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class. 
 
The traditional convolutional neural network usually initializes the weights of all network layers at one time before network training, and then updates the weights of the network by back-propagation algorithm to improve the accuracy of the network during network training. However, with the increase of network depth, the computational cost of this method will increase dramatically and the test accuracy will be affected. In order to solve this problem, a method of gradually reinitializing the weights of each layer is proposed, that is, after a certain training period, the weight of the previous layer is determined and remain unchanged, then initialize the weights of all subsequent layers, repeat this step until the weights of all layers are determined. In order to verify the performance of the method, a series of experiments were carried out on the CIFAR10 dataset. The results show that the accuracy of the network is improved by 9% and the training time is reduced by 29%. It shows that the method can improve the accuracy of the network and reduce the training time. [Improvement in Convolutional Neural Network for CIFAR-10 Dataset Image Classification] 
 
Training neural networks is a computationally challenging problem that requires significant time efforts. Two approaches are proposed that improve efficiency of this task by actively selecting most relevant points from a training data set. The first approach forms a batch that maximizes the reduction of the estimator’s entropy, while the second approach only trains on datapoints whose predicted probability is below a predetermined threshold. Both techniques rely on data metrics to speed up training while retaining the epoch based neural network training framework. The results demonstrate that the proposed methods enable significant reduction of training time in experiments on the CIFAR10 dataset without compromising the accuracy. [Improvement in Convolutional Neural Network for CIFAR-10 Dataset Image Classification] 
 
